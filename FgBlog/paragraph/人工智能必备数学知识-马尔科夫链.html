<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <div class="markdown-body"><!--166283742--><style>.markdown-body{word-break:break-word;line-height:1.75;font-weight:400;font-size:15px;overflow-x:hidden;color:#333}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{line-height:1.5;margin-top:35px;margin-bottom:10px;padding-bottom:5px}.markdown-body h1{font-size:30px;margin-bottom:5px}.markdown-body h2{padding-bottom:12px;font-size:24px;border-bottom:1px solid #ececec}.markdown-body h3{font-size:18px;padding-bottom:0}.markdown-body h4{font-size:16px}.markdown-body h5{font-size:15px}.markdown-body h6{margin-top:5px}.markdown-body p{line-height:inherit;margin-top:22px;margin-bottom:22px}.markdown-body img{max-width:100%}.markdown-body hr{border:none;border-top:1px solid #ddd;margin-top:32px;margin-bottom:32px}.markdown-body code{word-break:break-word;border-radius:2px;overflow-x:auto;background-color:#fff5f5;color:#ff502c;font-size:.87em;padding:.065em .4em}.markdown-body code,.markdown-body pre{font-family:Menlo,Monaco,Consolas,Courier New,monospace}.markdown-body pre{overflow:auto;position:relative;line-height:1.75}.markdown-body pre>code{font-size:12px;padding:15px 12px;margin:0;word-break:normal;display:block;overflow-x:auto;color:#333;background:#f8f8f8}.markdown-body a{text-decoration:none;color:#0269c8;border-bottom:1px solid #d1e9ff}.markdown-body a:active,.markdown-body a:hover{color:#275b8c}.markdown-body table{display:inline-block!important;font-size:12px;width:auto;max-width:100%;overflow:auto;border:1px solid #f6f6f6}.markdown-body thead{background:#f6f6f6;color:#000;text-align:left}.markdown-body tr:nth-child(2n){background-color:#fcfcfc}.markdown-body td,.markdown-body th{padding:12px 7px;line-height:24px}.markdown-body td{min-width:120px}.markdown-body blockquote{color:#666;padding:1px 23px;margin:22px 0;border-left:4px solid #cbcbcb;background-color:#f8f8f8}.markdown-body blockquote:after{display:block;content:""}.markdown-body blockquote>p{margin:10px 0}.markdown-body ol,.markdown-body ul{padding-left:28px}.markdown-body ol li,.markdown-body ul li{margin-bottom:0;list-style:inherit}.markdown-body ol li .task-list-item,.markdown-body ul li .task-list-item{list-style:none}.markdown-body ol li .task-list-item ol,.markdown-body ol li .task-list-item ul,.markdown-body ul li .task-list-item ol,.markdown-body ul li .task-list-item ul{margin-top:0}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-top:3px}.markdown-body ol li{padding-left:6px}.markdown-body .contains-task-list{padding-left:0}.markdown-body .task-list-item{list-style:none}@media (max-width:720px){.markdown-body h1{font-size:24px}.markdown-body h2{font-size:20px}.markdown-body h3{font-size:18px}}</style>
            <h1>马尔科夫链 - 强化学习的基础</h1>
            <h2>深度强化学习</h2>
            <p>深度学习神经网络模型 + 强化学习方法</p>
            <p>而马尔科夫链就是这个强化学习的基础</p>
            <p>那么这个马尔科夫链是什么呢</p>
            <h2>马尔科夫链</h2>
            <h3 id="one">定义</h3>
            <p>状态空间中，经过从一个状态到另一个状态的转换的随机过程，下一状态的概率分布只能由当前状态决定，且与它前面的时间均无关</p>
            <p>链这种东西就考虑以下区块链，每个链节点，记录了一定的交易信息，然后传到下一个链去大概就是这样。</p>
            <p>从概念上来说吼，你可能听的很莫名其妙，让我来稍微用自己的理解解释以下。就是呢，我们先举个不那么恰当的例子。还是用开车来假设，第一个链的状态记录的是你的车现在当前这个位置，有什么状态呢车速50，油门踩死，刹车坏了。前面100米斑马线有个人过马路，过马路的速度是5。然后呢第二个呢记录到行人受到了惊吓速度变成了20，你车突然刹车好了，踩下了刹车车速降到了20，和斑马线的距离剩下20。那么第三个状态就只能由你当前的这个状态去计算，比如第三个状态的刹车情况，有没有撞上人，这些的都不受第一个状态影响。</p>
            <p>唔</p>
            <p>我说了些屎，再举个例子，一个人随机的向左向右走（百分之50的概率）它走的下一个位置，只有当前的位置决定。我们就把这种一个个记录当前位置信息的状态链成为马尔科夫链。</p>
            <p>下面还是看看课件里的例子</p>
            <h3 id="two">样例</h3>
            <p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6627faca6d2e49af99a2bd433ea70bc3~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
            <p>我们来看看吼这个链，</p>
            <p>他就只有两种状态，晴和雨</p>
            <p>当天是晴，他第二天有可能是雨，也有可能是晴。但是只由前一天的天气决定。昨天的天气就完全没有作用了。</p>
            <p>然后呢我们怎么用它呢</p>
            <p>假设我们今天是晴天，预测后天的天气</p>
            <p>我们首先会知道明天晴雨的概率分别是[80 ,20]</p>
            <p>后天的天气是晴天的概率就是</p>
            <p><code>明天后天都是晴天的概率 + 明天下雨后天晴天的概率 = 0.8*0.8 + 0.2*0.5 = 0.74 </code></p>
            <p>后天的天气是阴天的概率就是</p>
            <p><code>明天后天都下雨的概率 + 明天晴天后天下雨的概率 = 0.2*0.5 + 0.8*0.2 = 0.26</code></p>
            <p>你看这两个数据相加等于1，就证明我们这样计算啊非常合理对不对。</p>
            <p>那再看看这个数据怎么来的呢</p>
            <pre><code>
明天的概率                    状态列成一个矩阵
                            [
[0.8,0.2]                   [0.8, 0.2],
                            [0.5, 0.5],
                            ]
                            
            </code></pre>
            <p>最后的结果是不是就很像明天的概率乘上状态矩阵</p>
            <pre><code>[0.8*0.8 + 0.2*0.5, 0.8*0.2 + 0.2*0.5]
            </code></pre>
            <p>忘了的就看看前面说的矩阵计算</p>
            <p>那是不是就有大后天的概率就是后天的概率乘状态矩阵</p>
            <p>[0.74,0.26]乘那个矩阵就完事了</p>
            <h3>状态转移矩阵</h3>
            <p>再来一个数据多点的试试</p>
            <p><img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ea3d251ada6f4deca127ac49dc1ea248~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
            <p>来试试吼，假设今天是晴天，求后天的天气概率</p>
            <p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/89bba6bb3e8948a7a525dea1f1609231~tplv-k3u1fbpfcp-watermark.image" alt="makov1.jpeg"></p>
            <p>这是直接用矩阵乘的（看到这个写字板了吗，赞助商打钱！！！我可以推广，学习真的很好用），我们再来分析以下，真实情况概率的计算</p>
            <p>假设</p>
            <pre><code>
明天晴0.7后天的晴天概率就是0.7*0.7

明天阴天0.2后天是晴天的概率就是0.2*0.4

明天下雨0.1后天晴天的概率就是0.1*0.2

那么一相加就是0.59
            </code></pre>
            <p>好像很对的样子，那是当然的因为别人就是这么教的，只是象征性的对推一下，后面的就不算敲了啊，不相信的自己可以验证一下</p>
            <h2 id="three">马尔科夫链收敛和平稳条件</h2>
            <p>1、可能状态数是有限的，就是说这个矩阵吼，你不能是无限的，不然没法弄</p>
            <p>2、二状态间的转移概率需要稳定不变，就是你不能像我一开始的那样刹车突然修好了，又突然坏了，你要给一个刹车好的时候坏的概率，坏的时候好的概率，而且这个概率要固定的不能变</p>
            <p>3、任意状态能转变到任意状态，就是吼你不能规定天气只能从晴天到阴天到雨天，她也可以从晴天直接到雨天</p>
            <p>4、不能是简单的循还，就是不能是晴到雨到雨到晴到雨，这就完全没有概率的情况了，就是第二天一定是晴，这状态矩阵就是[[1,0],[0,1]]</p>
            <h2 id="four">马尔科夫奖励过程</h2>
            <p>马尔可夫奖励过程（Markov Process）主要描述的是状态之间的转移关系，在各个状态的转移过程中，赋予不同的奖励值就得到了马尔可夫奖励过程。由一个四元组组成(S, P,R ,伽马 )</p>
            <p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fc75cd674e8247019fc919b35e09cf68~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
            <h2 id="five">马尔科夫决策过程</h2>
            <p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6856c85e63204bae962f8a0e646a23cb~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
            <p>这就是我刚才说的开车模型了，就是把做出的决定，比如踩刹车等不同的决策加入模型里，也是修改状态的一个部分。根据不同的决策获得奖励也不一样</p>
            <p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5547d8a26cae4127a2c0beaf5bd0d813~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
            <p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e93b3df9b2f040808f62859ae05b4130~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
            <p>这个我觉得我没消化完我的学的东西，我尽力来解释一下吼
            首先我们看那个图，就右边那副图。</p>
            <p>对于机器人向左向右向上下向下是每个不同的状态合集都有百分之25</p>
            <p>当机器人走出4x4的框框，就给予-10的奖励</p>
            <p>决策就是机器人的动作，我们现在规定机器人只有一个拾取的动作，在空地拾取奖励是-5，在空地不拾取的奖励是5，在陷阱拾取奖励是-100，在宝箱拾取是100</p>
            <p>在机器不停的改变状态不停的选择是否拾取的过程中，就会得到不同的奖励反馈。而强化学习的目标就是就是把期望也就是奖励最大化。</p>
            <p>给一个别人的讲解<a href="https://stepneverstop.github.io/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B9%8BMDP%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B.html" target="_blank" rel="nofollow noopener noreferrer"></a><a href="https://stepneverstop.github.io/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B9%8BMDP%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B.html" target="_blank" rel="nofollow noopener noreferrer">https://stepneverstop.github.io/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E4%B9%8BMDP%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B.html</a></p>
            <p>至于具体的应用，就在后面慢慢学哈，人工智能必备数学知识就到这了。下一章就开始将</p><!--2125-->
<style>.markdown-body pre,.markdown-body pre>code.hljs{color:#333;background:#f8f8f8}.hljs-comment,.hljs-quote{color:#998;font-style:italic}.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#333;font-weight:700}.hljs-literal,.hljs-number,.hljs-tag .hljs-attr,.hljs-template-variable,.hljs-variable{color:teal}.hljs-doctag,.hljs-string{color:#d14}.hljs-section,.hljs-selector-id,.hljs-title{color:#900;font-weight:700}.hljs-subst{font-weight:400}.hljs-class .hljs-title,.hljs-type{color:#458;font-weight:700}.hljs-attribute,.hljs-name,.hljs-tag{color:navy;font-weight:400}.hljs-link,.hljs-regexp{color:#009926}.hljs-bullet,.hljs-symbol{color:#990073}.hljs-built_in,.hljs-builtin-name{color:#0086b3}.hljs-meta{color:#999;font-weight:700}.hljs-deletion{background:#fdd}.hljs-addition{background:#dfd}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}</style></div>
</body>
</html>
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <div class="markdown-body"><!--166283742--><style>.markdown-body{word-break:break-word;line-height:1.75;font-weight:400;font-size:15px;overflow-x:hidden;color:#333}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{line-height:1.5;margin-top:35px;margin-bottom:10px;padding-bottom:5px}.markdown-body h1{font-size:30px;margin-bottom:5px}.markdown-body h2{padding-bottom:12px;font-size:24px;border-bottom:1px solid #ececec}.markdown-body h3{font-size:18px;padding-bottom:0}.markdown-body h4{font-size:16px}.markdown-body h5{font-size:15px}.markdown-body h6{margin-top:5px}.markdown-body p{line-height:inherit;margin-top:22px;margin-bottom:22px}.markdown-body img{max-width:100%}.markdown-body hr{border:none;border-top:1px solid #ddd;margin-top:32px;margin-bottom:32px}.markdown-body code{word-break:break-word;border-radius:2px;overflow-x:auto;background-color:#fff5f5;color:#ff502c;font-size:.87em;padding:.065em .4em}.markdown-body code,.markdown-body pre{font-family:Menlo,Monaco,Consolas,Courier New,monospace}.markdown-body pre{overflow:auto;position:relative;line-height:1.75}.markdown-body pre>code{font-size:12px;padding:15px 12px;margin:0;word-break:normal;display:block;overflow-x:auto;color:#333;background:#f8f8f8}.markdown-body a{text-decoration:none;color:#0269c8;border-bottom:1px solid #d1e9ff}.markdown-body a:active,.markdown-body a:hover{color:#275b8c}.markdown-body table{display:inline-block!important;font-size:12px;width:auto;max-width:100%;overflow:auto;border:1px solid #f6f6f6}.markdown-body thead{background:#f6f6f6;color:#000;text-align:left}.markdown-body tr:nth-child(2n){background-color:#fcfcfc}.markdown-body td,.markdown-body th{padding:12px 7px;line-height:24px}.markdown-body td{min-width:120px}.markdown-body blockquote{color:#666;padding:1px 23px;margin:22px 0;border-left:4px solid #cbcbcb;background-color:#f8f8f8}.markdown-body blockquote:after{display:block;content:""}.markdown-body blockquote>p{margin:10px 0}.markdown-body ol,.markdown-body ul{padding-left:28px}.markdown-body ol li,.markdown-body ul li{margin-bottom:0;list-style:inherit}.markdown-body ol li .task-list-item,.markdown-body ul li .task-list-item{list-style:none}.markdown-body ol li .task-list-item ol,.markdown-body ol li .task-list-item ul,.markdown-body ul li .task-list-item ol,.markdown-body ul li .task-list-item ul{margin-top:0}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-top:3px}.markdown-body ol li{padding-left:6px}.markdown-body .contains-task-list{padding-left:0}.markdown-body .task-list-item{list-style:none}@media (max-width:720px){.markdown-body h1{font-size:24px}.markdown-body h2{font-size:20px}.markdown-body h3{font-size:18px}}</style>
        <div class="markdown-body">
            <h2>kNN-k近邻分类模型</h2>
            <p>还是从一个问题开始</p>
            <p  id="one"><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/be55553183a14ecebda649a0e660bbfd~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
            <p>不讨论这个问题，就先根据模型，不妨这样思考一下：</p>
            <p>我们判断人种，有黑人、白人、黄人、和外星人四个分类。当我们把需要确定的人，放在广州的一个黑人社区里。</p>
            <p>如果我们设置范围就是这个社区里，那么我们就可以认为他是个黑人的概率很大，就会把他分到黑人里</p>
            <p>加入我们把范围加大到整个中国，那么我们可能会认为他是个黄人。</p>
            <p>诶如果我们再把范围扩散到全球，我们就会倾向于他是个白人，因为白人在全球的比例是43%，黄人41%，黑人16%。</p>
            <p>如果再把他放大到无穷大的全宇宙，根据模型，我们就会更倾向于他是一个外星人。</p>
            <p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/66c0ddbd1bc34973986608b2a2ea7b37~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
            <p>诶诶诶诶诶，是不是觉得有点问题。是不是想说，今天就算把我头砍下来，他也不可能是个外星人。</p>
            <p>所以我们就先带着这个问题，看看这个kNN模型算法步骤</p>
            <h2 id="two">kNN模型算法步骤</h2>
            <p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e978698e45ca4b89880247aa65779051~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
            <p>我们先看这个步骤</p>
            <p>训练数据集D：他是一个x为特征向量，就是我们刚才说的坐标（广州黑人社区），y为数据类别（黑白黄外）。</p>
            <p>然后我们现在有了很多样本，比如黑人社区里的有</p>
            <p><code>（1栋302，黄），（2栋302，黑），（3栋302，黑），（4栋302，黑）......</code></p>
            <p>然后全广州的数据就更大了</p>
            <p>这个时候我们收到了一个新的样本数据<code>（小区公园，y）</code></p>
            <p>我们需要对这个y做出判断</p>
            <p>(1)要收集每个样本与新数据的x：（小区公园）的距离d</p>
            <p>(2)将计算出的这个距离按照升序排列，并按照排序取前K个样本</p>
            <p>(3)统计这K个样本的y值，并找出频率最高的标签</p>
            <p>(4)最后确定这个<code>（小区公园，y）</code>的y是哪个类型</p>
            <p>这个时候，细心的人可能就有第二个问题了</p>
            <p>这个距离d他有问题</p>
            <p>他有什么问题呢，我们都知道地球呢，他是圆的！</p>
            <p>圆的有什么问题呢，你想想他可能从广州到美国的距离坐飞机是这个距离，从地底走一个直线距离，诶他就会短很多。</p>
            <p>所以我们在这里再说说kNN里的距离计算方式</p>
            <h2 id="three">kNN里的距离计算方式</h2>
            <h3>欧式距离</h3>
            <p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c3962ca3129e4f76940fe1531b171e7a~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
            <p>这个就是实打实的，挖土走地底的直线距离，注意一下，这个（x,y）吼，是他数据特征对应过来就是这个人所在对于地球的（x,y,z）的坐标
            ，不是刚才说的（特征，结果）</p>
            <h3>曼哈顿距离</h3>
            <p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b2e2621069a4494280f8f818a993b7c1~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
            <p>有了刚才的欧式距离，是不是这个就很好理解了，这就是你实打实的那种要走的距离</p>
            <p>距离就先说到这，还有其他的距离我们先不考虑</p>
            <h2 id="four">看一个kNN的分类图</h2>
            <p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a7903f521f324180b4efc28bf8a8be10~tplv-k3u1fbpfcp-watermark.image" alt="image.png"></p>
            <p>这图上面的k，就是从近到远取得值的数量。我们可以看到如果是k=1，他的决策边界是不是非常的曲折。</p>
            <p>我们想象一下，还是刚才那个黑人社区，我们一户黑人一户黄人又两户黑人的又三户黄人的。我们是不是这个边界就很难划分，就一栋楼之间都能拐三四个弯，但是我们是不是如果取k=20，诶这栋楼黑人多，那栋楼黑人少，这样根据这个人在哪栋楼就更好去判断他是个黑人还是个黄人。分类边界就在楼之间画。</p>
            <p>所以我们可以得出这个k值越小，分类边界就越曲折，越容易被噪声干扰，也就是抗干扰能力越差。</p>
            <p>但是呢，如果取得太大，就会出现这个人是个外星人的结论</p>
            <p><code>由于课程里没有说这个问题，我们就自己百度一下来解决</code></p>
            <h2 id="five">网上抄的</h2>
            <p>如果我们选取较小的k值，就相当于用较小的邻域中的训练实例进行预测，“学习”的近似误差会减小，只有与输入实例较近的训练实例才会对预测结果起作用。但缺点是“学习”的估计误差会增大，预测结果对邻近的实例点非常敏感。如果邻近的实例点恰巧时候噪声，预测就会出错。换句话说，k值的减小意味着整体模型变得复杂，容易发生过拟合。</p>
            <p>如果不太理解k值小模型就复杂，我们不妨假设k=N，N为训练集大小，那么无论输入实例是什么，都将简单的预测它属于在训练实例中最多的类，这显然是不合理的。这时的模型是非常简单的，完全忽略训练实例中的大量有用信息。</p>
            <p>如果选择较大的k值，就相当于用较大的邻域中的训练实例进行预测，其优点是可以可以减小“学习”的估计误差，但缺点是“学习”的近似误差会增大。这时与输入实例较远的训练实例也会对预测结果起作用，使预测发生错误。k值增大就意味着整体的模型变得简单。
            在应用中，k值一般取一个较小的数值，通常采用交叉验证法来选取最优的k值。
            ————————————————
            版权声明：本文为CSDN博主「BlackEyes_SGC」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
            原文链接：<a href="https://blog.csdn.net/u011204487/article/details/105890168" target="_blank" rel="nofollow noopener noreferrer">https://blog.csdn.net/u011204487/article/details/105890168</a></p>
            <h2 id="six">交叉验证法</h2>
            <p>交叉验证（Cross Validation），有的时候也称作循环估计（Rotation Estimation），是一种统计学上将数据样本切割成较小子集的实用方法，该理论是由Seymour Geisser提出的。
            在给定的建模样本中，拿出大部分样本进行建模型，留小部分样本用刚建立的模型进行预报，并求这小部分样本的预报误差，记录它们的平方加和。这个过程一直进行，直到所有的样本都被预报了一次而且仅被预报一次。把每个样本的预报误差平方加和，称为PRESS(predicted Error Sum of Squares)。</p>
            <p>是不是看不懂，我也看不懂，但是可以强行理解一下</p>
            <p>我们把范围先确定为全球，计算一个误差，去评价一下这个模型</p>
            <p>然后缩小范围，比如按所在的大洲，比如这个广州的我们就选亚洲做范围，其他地方的就选所在的大洲，计算出一个误差，去评价模型</p>
            <p>再缩小范围，选国家，选城市。到最后我们选出误差最小的k去做为这个模型使用的k</p>
            <p>我找了个应用这个交叉验证的文章，先留着以后看的懂的时候再看看</p>
            <p><code>kNN处理iris数据集-使用交叉验证方法确定最优 k 值</code><a href="https://blog.csdn.net/woswod/article/details/79881425" target="_blank" rel="nofollow noopener noreferrer">https://blog.csdn.net/woswod/article/details/79881425</a></p>
            <p>就把这个问题算解决了，先继续往下学习</p><!--1381--></div>
<style>.markdown-body pre,.markdown-body pre>code.hljs{color:#333;background:#f8f8f8}.hljs-comment,.hljs-quote{color:#998;font-style:italic}.hljs-keyword,.hljs-selector-tag,.hljs-subst{color:#333;font-weight:700}.hljs-literal,.hljs-number,.hljs-tag .hljs-attr,.hljs-template-variable,.hljs-variable{color:teal}.hljs-doctag,.hljs-string{color:#d14}.hljs-section,.hljs-selector-id,.hljs-title{color:#900;font-weight:700}.hljs-subst{font-weight:400}.hljs-class .hljs-title,.hljs-type{color:#458;font-weight:700}.hljs-attribute,.hljs-name,.hljs-tag{color:navy;font-weight:400}.hljs-link,.hljs-regexp{color:#009926}.hljs-bullet,.hljs-symbol{color:#990073}.hljs-built_in,.hljs-builtin-name{color:#0086b3}.hljs-meta{color:#999;font-weight:700}.hljs-deletion{background:#fdd}.hljs-addition{background:#dfd}.hljs-emphasis{font-style:italic}.hljs-strong{font-weight:700}</style></div>
</body>
</html>